# Image-Captioning


This project builds an image-captioning model using a Vision encoder + Transformer decoder architecture trained on COCO Captions. It includes: code to download the COCO dataset (train/val images + annotations), data preprocessing, tokenizer setup, model implementation, training loop, and a small inference demo.
